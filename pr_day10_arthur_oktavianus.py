# -*- coding: utf-8 -*-
"""PR_day10_Arthur Oktavianus.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IvfEsAER_QKqi9cxpyxnSoaX9pCTNgeV

# Machine Learning Projects Portofolio
### Ketentuan Tugas :
1. Dibebaskan untuk men-download Dataset dari Kaggle atau sumber data lainnya, pilih untuk kasus supervised atau unsupervised.
2. Buatlah End to end project Machine Learning di local jupyter notebook / Google Collaboratory.
3. Ganti nama file : template_pr_day10.ipynb  dengan PR_day10_nama_siswa.ipynb
4. Upload Dataset yang digunakan ke Kaggle
5. Upload file code dan ppt (jika ada) ke dalam github repository + file readme pada github.
6. Tugas ini bersifat individu, dikumpulkan ke LMS dalam bentuk **link githubnya saja**.

#Import libraries and dataset
"""

import pandas as pd
import seaborn as sns
sns.set()

"""# Mengimpor dataset"""

from sklearn.datasets import load_breast_cancer
kanker = load_breast_cancer()

# Menggabungkan ke dalam satu data frame
df_kanker = pd.DataFrame(kanker['data'], columns = kanker['feature_names'])
df_kanker['status'] = kanker['target']

"""# EDA Terhadap Dataset Kanker Payudara Secara Keseluruhan

### Informasi dasar tentang dataset
"""

print("Info Dataset:")
print(df_kanker.info())

"""### Statistik deskriptif"""

print("\nStatistik Deskriptif:")
print(df_kanker.describe())

"""### Periksa Missing Values"""

print("\nJumlah Missing Values:")
print(df_kanker.isnull().sum())

"""# Visualisasi data"""

sns.pairplot(df_kanker, vars = ['mean radius', 'mean texture', 'mean area', 'mean perimeter', 'mean smoothness'], hue = 'status' )

# Plot korelasi dengan heatmap
sns.heatmap(df_kanker[['mean radius', 'mean texture', 'concavity error', 'mean area','mean smoothness']].corr(), annot=True, cmap='bwr')

"""# Analisis distribusi kelas"""

plt.figure(figsize=(6, 4))
sns.countplot(data=df_kanker, x='status')
plt.title('Distribusi Kelas Target')
plt.xlabel('Status (0: Benign, 1: Malignant)')
plt.ylabel('Jumlah')

# Tambahkan label dengan persentase untuk setiap kelas
total = len(df_kanker)
for p in plt.gca().patches:
    height = p.get_height()
    plt.text(p.get_x() + p.get_width() / 2., height + 5, f'{height / total:.1%}', ha='center')

plt.show()

"""Dari hasil distribusi di atas, terlihat data set disimpulkan **tidak balanced**, karena proporsi  62.7% dengan 37.3%

# Split Data Set
"""

X = df_kanker.drop(['status'],axis=1)
y = df_kanker['status']

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)

"""# Feature Scaling"""

from sklearn.preprocessing import StandardScaler
sc_X = StandardScaler()
X_train = sc_X.fit_transform(X_train)
X_test = sc_X.transform(X_test)

"""# Melakukan Modeling dengna SVM dan Logistik Regresi"""

from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix

# Training dengan SVM
svm_classifier = SVC(kernel='rbf', random_state=0)
svm_classifier.fit(X_train, y_train)

# Training dengan Regresi Logistik
logistic_classifier = LogisticRegression(random_state=0)
logistic_classifier.fit(X_train, y_train)

from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Evaluasi model SVM
svm_y_predict = svm_classifier.predict(X_test)
svm_cm = confusion_matrix(y_test, svm_y_predict)
plt.figure(figsize=(5, 4))
sns.heatmap(svm_cm, annot=True)
plt.title('Confusion Matrix for SVM')
plt.show()
print("Classification Report for SVM:")
print(classification_report(y_test, svm_y_predict))

# Evaluasi model Regresi Logistik
logistic_y_predict = logistic_classifier.predict(X_test)
logistic_cm = confusion_matrix(y_test, logistic_y_predict)
plt.figure(figsize=(5, 4))
sns.heatmap(logistic_cm, annot=True)
plt.title('Confusion Matrix for Logistic Regression')
plt.show()
print("Classification Report for Logistic Regression:")
print(classification_report(y_test, logistic_y_predict))

"""# Kesimpulan untuk Base line:

### SVM:

**Precision:** Precisi untuk kelas 0 (benign) adalah 1.00 dan untuk kelas 1 (malignant) adalah 0.97. Ini menunjukkan bahwa SVM memiliki tingkat kesalahan yang sangat rendah dalam mengklasifikasikan contoh positif (malignant).

**Recall:** Recall untuk kelas 0 adalah 0.96 dan untuk kelas 1 adalah 1.00. SVM memiliki kemampuan yang sangat baik untuk mendeteksi kelas 1 (malignant) dengan recall yang sempurna.
    
**F1-score:** F1-score yang tinggi menunjukkan bahwa SVM memiliki keseimbangan yang baik antara precision dan recall untuk kedua kelas.
    
**Akurasi:** Akurasi keseluruhan adalah 0.98, yang menunjukkan bahwa SVM sangat baik dalam memprediksi kelas yang benar dari keseluruhan sampel.

### Regresi Logistik:

**Precision:** Precisi untuk kelas 0 adalah 0.96 dan untuk kelas 1 adalah 0.97. Regresi Logistik memiliki tingkat kesalahan yang rendah dalam mengklasifikasikan kedua.

**Recall:** Recall untuk kedua kelas adalah 0.96 dan 0.97, menunjukkan bahwa Regresi Logistik memiliki kemampuan yang baik dalam mendeteksi kedua kelas.
    
**F1-score:** F1-score yang tinggi menunjukkan bahwa Regresi Logistik memiliki keseimbangan yang baik antara precision dan recall untuk kedua kelas.
    
**Akurasi:** Akurasi keseluruhan adalah 0.96, menunjukkan bahwa Regresi Logistik juga memiliki kinerja yang baik dalam memprediksi kelas yang benar dari keseluruhan sampel.

## Kedua model memiliki performa yang sangat baik dengan akurasi yang tinggi dan skor F1 yang seimbang untuk kedua kelas. Namun, dalam hal akurasi, **SVM** memiliki sedikit keunggulan dibandingkan dengan Regresi Logistik.

# Hyperparameter Tuning

## Hyperparameter untuk SVM dengan Grid Search atau Random Search
"""

from sklearn.model_selection import GridSearchCV

# Definisikan grid parameter yang akan diuji
param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001], 'kernel': ['rbf', 'linear', 'poly', 'sigmoid']}

# Inisialisasi model SVM
svm_classifier_tuned = SVC(random_state=0)

# Buat objek GridSearchCV
grid_search = GridSearchCV(svm_classifier_tuned, param_grid, cv=5, scoring='accuracy')

# Lakukan penyetelan hyperparameter
grid_search.fit(X_train, y_train)

# Simpan parameter terbaik yang ditemukan
print("Hyperparameter terbaik untuk SVM:", grid_search.best_params_)

# Evaluasi model SVM yang telah disetel ulang
svm_y_predict_tuned = grid_search.predict(X_test)
svm_cm_tuned = confusion_matrix(y_test, svm_y_predict_tuned)
plt.figure(figsize=(5, 4))
sns.heatmap(svm_cm_tuned, annot=True)
plt.title('Confusion Matrix for Tuned SVM')
plt.show()
print("Classification Report for Tuned SVM:")
print(classification_report(y_test, svm_y_predict_tuned))

"""## Hyperparameter untuk Regresi Logistik"""

# Definisikan grid parameter yang akan diuji
param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'penalty': ['l1', 'l2']}

# Inisialisasi model Regresi Logistik
logistic_classifier_tuned = LogisticRegression(random_state=0, solver='liblinear')

# Buat objek GridSearchCV
grid_search = GridSearchCV(logistic_classifier_tuned, param_grid, cv=5, scoring='accuracy')

# penyetelan hyperparameter
grid_search.fit(X_train, y_train)

# simpan parameter terbaik yang ditemukan
print("Hyperparameter terbaik untuk Regresi Logistik:", grid_search.best_params_)

# Evaluasi model Regresi Logistik yang telah disetel ulang
logistic_y_predict_tuned = grid_search.predict(X_test)
logistic_cm_tuned = confusion_matrix(y_test, logistic_y_predict_tuned)
plt.figure(figsize=(5, 4))
sns.heatmap(logistic_cm_tuned, annot=True)
plt.title('Confusion Matrix for Tuned Logistic Regression')
plt.show()
print("Classification Report for Tuned Logistic Regression:")
print(classification_report(y_test, logistic_y_predict_tuned))

"""# Kesimpulan

## Dari Hasil base line maupun hyperparameter tuning untuk ke dua model menunjukan hasil yang sama, yang berarti untuk hasil dari kedua model tersebut sudah mencapai titik optimumnya, hal tersebut terlihat  ketika dilakukan hyperparameter tidak ada penambahan kemampuan prediktifnya. Terimakasih
"""